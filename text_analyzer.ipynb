{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-oqJNQERtE2C"
      },
      "outputs": [],
      "source": [
        "!pip install python-docx PyPDF2 antiword\n",
        "\n",
        "import re\n",
        "import string\n",
        "from collections import Counter\n",
        "import requests\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# For PDF files\n",
        "try:\n",
        "    import PyPDF2\n",
        "except:\n",
        "    !pip install PyPDF2\n",
        "    import PyPDF2\n",
        "\n",
        "# For DOCX files\n",
        "try:\n",
        "    import docx\n",
        "except:\n",
        "    !pip install python-docx\n",
        "    import docx\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_txt_file(file_path):\n",
        "    \"\"\"Read text from .txt file\"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            return file.read()\n",
        "    except UnicodeDecodeError:\n",
        "        with open(file_path, 'r', encoding='latin-1') as file:\n",
        "            return file.read()\n",
        "\n",
        "def read_docx_file(file_path):\n",
        "    \"\"\"Read text from .docx file\"\"\"\n",
        "    doc = docx.Document(file_path)\n",
        "    text = []\n",
        "    for paragraph in doc.paragraphs:\n",
        "        if paragraph.text.strip():\n",
        "            text.append(paragraph.text)\n",
        "    return '\\n'.join(text)\n",
        "\n",
        "def read_pdf_file(file_path):\n",
        "    \"\"\"Read text from .pdf file\"\"\"\n",
        "    text = \"\"\n",
        "    with open(file_path, 'rb') as file:\n",
        "        pdf_reader = PyPDF2.PdfReader(file)\n",
        "        for page in pdf_reader.pages:\n",
        "            page_text = page.extract_text()\n",
        "            if page_text:\n",
        "                text += page_text + \"\\n\"\n",
        "    return text\n",
        "\n",
        "def read_doc_file(file_path):\n",
        "    \"\"\"Read text from .doc file using antiword\"\"\"\n",
        "    try:\n",
        "        # Use antiword command-line tool for .doc files\n",
        "        !apt-get install antiword > /dev/null 2>&1\n",
        "        text = !antiword -w 0 \"{file_path}\" 2>/dev/null\n",
        "        return '\\n'.join(text)\n",
        "    except:\n",
        "        return \"Unable to read .doc file content. Please convert to .docx or .txt format.\"\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"Clean and preprocess text for analysis\"\"\"\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    # Remove numbers and extra whitespace\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = ' '.join(text.split())\n",
        "    return text\n",
        "\n",
        "def analyze_text(text):\n",
        "    \"\"\"Analyze text and return statistics\"\"\"\n",
        "    if not text or text.startswith(\"Unable to read\") or text.startswith(\"Error\"):\n",
        "        return {\n",
        "            'lines': 0,\n",
        "            'words': 0,\n",
        "            'characters': 0,\n",
        "            'top_5_words': [],\n",
        "            'error': text\n",
        "        }\n",
        "\n",
        "    # Basic statistics\n",
        "    lines = [line for line in text.split('\\n') if line.strip()]\n",
        "    words = text.split()\n",
        "    characters = len(text.replace('\\n', '').replace('\\r', '').replace(' ', ''))\n",
        "\n",
        "    # Clean text for word frequency analysis\n",
        "    cleaned_text = clean_text(text)\n",
        "    word_list = [word for word in cleaned_text.split() if len(word) > 1]\n",
        "\n",
        "    # Word frequency\n",
        "    word_freq = Counter(word_list)\n",
        "    top_5_words = word_freq.most_common(5)\n",
        "\n",
        "    return {\n",
        "        'lines': len(lines),\n",
        "        'words': len(words),\n",
        "        'characters': characters,\n",
        "        'top_5_words': top_5_words,\n",
        "        'error': None\n",
        "    }\n",
        "\n",
        "def process_file(file_path):\n",
        "    \"\"\"Process file based on its extension\"\"\"\n",
        "    file_extension = file_path.lower().split('.')[-1]\n",
        "\n",
        "    print(f\"Processing {file_extension.upper()} file...\")\n",
        "\n",
        "    if file_extension == 'txt':\n",
        "        return read_txt_file(file_path)\n",
        "    elif file_extension == 'docx':\n",
        "        return read_docx_file(file_path)\n",
        "    elif file_extension == 'pdf':\n",
        "        return read_pdf_file(file_path)\n",
        "    elif file_extension == 'doc':\n",
        "        return read_doc_file(file_path)\n",
        "    else:\n",
        "        return f\"Unsupported file format: {file_extension}\"\n",
        "\n",
        "def display_results(stats, filename):\n",
        "    \"\"\"Display analysis results in a formatted way\"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"üìä TEXT ANALYSIS REPORT: {filename}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    if stats['error']:\n",
        "        print(f\"‚ùå Error: {stats['error']}\")\n",
        "        print(\"=\" * 60)\n",
        "        return\n",
        "\n",
        "    print(f\"üìà Basic Statistics:\")\n",
        "    print(f\"   ‚Ä¢ Number of lines: {stats['lines']:,}\")\n",
        "    print(f\"   ‚Ä¢ Number of words: {stats['words']:,}\")\n",
        "    print(f\"   ‚Ä¢ Number of characters: {stats['characters']:,}\")\n",
        "\n",
        "    if stats['top_5_words']:\n",
        "        print(f\"\\nüèÜ Top 5 Most Frequent Words:\")\n",
        "        for i, (word, count) in enumerate(stats['top_5_words'], 1):\n",
        "            print(f\"   {i}. '{word}' - {count} occurrence(s)\")\n",
        "    else:\n",
        "        print(f\"\\n‚ÑπÔ∏è  No words found for frequency analysis\")\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "# Main function to run the text analyzer\n",
        "def text_analyzer():\n",
        "    \"\"\"Main function to run the text analyzer\"\"\"\n",
        "    print(\"üéØ TEXT ANALYZER PROJECT\")\n",
        "    print(\"=\" * 40)\n",
        "    print(\"Supported formats: .txt, .docx, .pdf\")\n",
        "    print(\".doc files have limited support\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    print(\"\\nChoose an option:\")\n",
        "    print(\"1. üìÅ Upload a file\")\n",
        "    print(\"2. ‚å®Ô∏è Enter text manually\")\n",
        "    print(\"3. üìö Analyze multiple files\")\n",
        "\n",
        "    choice = input(\"\\nEnter your choice (1-3): \").strip()\n",
        "\n",
        "    if choice == '1':\n",
        "        # File upload option\n",
        "        print(\"\\nPlease upload your file:\")\n",
        "        uploaded = files.upload()\n",
        "\n",
        "        if not uploaded:\n",
        "            print(\"‚ùå No file uploaded!\")\n",
        "            return\n",
        "\n",
        "        filename = list(uploaded.keys())[0]\n",
        "\n",
        "        try:\n",
        "            # Save uploaded file temporarily\n",
        "            with open(filename, 'wb') as f:\n",
        "                f.write(uploaded[filename])\n",
        "\n",
        "            # Process the file\n",
        "            text = process_file(filename)\n",
        "            stats = analyze_text(text)\n",
        "            display_results(stats, filename)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error processing file: {str(e)}\")\n",
        "\n",
        "    elif choice == '2':\n",
        "        # Manual text input\n",
        "        print(\"\\nEnter your text (press Enter twice to finish):\")\n",
        "        lines = []\n",
        "        while True:\n",
        "            line = input()\n",
        "            if line == '' and lines and lines[-1] == '':\n",
        "                break\n",
        "            lines.append(line)\n",
        "\n",
        "        text = '\\n'.join(lines[:-1])  # Remove the last empty line\n",
        "        stats = analyze_text(text)\n",
        "        display_results(stats, \"Manual Input\")\n",
        "\n",
        "    elif choice == '3':\n",
        "        # Analyze multiple files\n",
        "        analyze_multiple_files()\n",
        "\n",
        "    else:\n",
        "        print(\"‚ùå Invalid choice!\")\n",
        "\n",
        "def analyze_multiple_files():\n",
        "    \"\"\"Analyze multiple files at once\"\"\"\n",
        "    print(\"\\nüìö Upload multiple files for analysis:\")\n",
        "    uploaded_files = files.upload()\n",
        "\n",
        "    if not uploaded_files:\n",
        "        print(\"‚ùå No files uploaded!\")\n",
        "        return\n",
        "\n",
        "    results = {}\n",
        "    for filename, content in uploaded_files.items():\n",
        "        print(f\"\\nProcessing {filename}...\")\n",
        "        try:\n",
        "            # Save uploaded file temporarily\n",
        "            with open(filename, 'wb') as f:\n",
        "                f.write(content)\n",
        "\n",
        "            # Process the file\n",
        "            text = process_file(filename)\n",
        "            stats = analyze_text(text)\n",
        "            results[filename] = stats\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error processing {filename}: {str(e)}\")\n",
        "            results[filename] = {'error': str(e)}\n",
        "\n",
        "    # Display all results\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"üìä MULTIPLE FILES ANALYSIS SUMMARY\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    for filename, stats in results.items():\n",
        "        display_results(stats, filename)\n",
        "\n",
        "# Quick analyzer function for direct use\n",
        "def quick_analyze():\n",
        "    \"\"\"Quick analysis function for immediate use\"\"\"\n",
        "    uploaded = files.upload()\n",
        "    if not uploaded:\n",
        "        print(\"‚ùå No file uploaded!\")\n",
        "        return\n",
        "\n",
        "    filename = list(uploaded.keys())[0]\n",
        "    with open(filename, 'wb') as f:\n",
        "        f.write(uploaded[filename])\n",
        "\n",
        "    text = process_file(filename)\n",
        "    stats = analyze_text(text)\n",
        "    display_results(stats, filename)\n",
        "\n",
        "# Run the text analyzer\n",
        "if __name__ == \"__main__\":\n",
        "    text_analyzer()"
      ],
      "metadata": {
        "id": "CXZ6_fCAucS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cInAwN19t0PF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}